--- sentiment_analysis_agent/agent_core/agent.py	2023-05-03 00:00:00
+++ sentiment_analysis_agent/agent_core/agent.py	2023-05-03 00:00:00
@@ -173,26 +173,6 @@
         raise exception # Reraise exception in the main thread
     return result
 
-@tool("RedditDataTool")
-def fetch_reddit_data_tool(subreddit: str, limit: int = 15, session_id: str = None) -> str:
-  """Fetch recent posts from a specified subreddit using MCP.
-
-  Args:
-    subreddit: The name of the subreddit to fetch posts from (e.g., 'Bitcoin').
-    limit: Maximum number of posts to fetch. Defaults to 15 if not specified by the agent.
-    session_id: Session identifier (for tracking purposes). Optional - will use a default if not provided.
-
-  Returns:
-    JSON string containing post data or an error message in JSON format: {"error": "description"}.
-  """
-  logger.info(f"Executing sync tool wrapper for RedditDataTool (r/{subreddit}, limit={limit})")
-  
-  # Just call our direct implementation function
-  return get_reddit_data(subreddit, limit, session_id)
-
 class SentimentAnalysisAgent:
   """Agent that analyzes Bitcoin sentiment based on Reddit data."""
 
@@ -200,6 +180,10 @@
     self.model = CrewAILLM(model="gemini/gemini-2.0-flash-lite", api_key=get_api_key())
     
     # Import the proper RedditDataTool
+    from .crewai_tools import RedditDataTool
+    self.reddit_tool = RedditDataTool()
+    
+    # --- Define Templates for dynamic roles/goals/tasks ---
     self.agent_role_template = "{crypto_name} Sentiment Analyst"
     self.agent_goal_template = (
         "Analyze Reddit data from r/{subreddit} to determine the current sentiment around {crypto_name}. "
@@ -253,7 +237,7 @@
         goal=dynamic_goal,
         backstory=dynamic_backstory,
         verbose=False,
-        allow_delegation=False,
-        tools=[fetch_reddit_data_tool], # Use the sync wrapper tool
+        allow_delegation=False,
+        tools=[self.reddit_tool], # Use the proper RedditDataTool instance
         llm=self.model,
     )

--- /dev/null	2023-05-03 00:00:00
+++ sentiment_analysis_agent/agent_core/crewai_tools.py	2023-05-03 00:00:00
@@ -0,0 +1,40 @@
+"""CrewAI tool implementations for the Reddit data tool."""
+
+import logging
+import json
+import traceback
+import time
+from typing import Any, Dict, List, Optional
+
+# Import from crewai properly
+from crewai.tools import BaseTool
+
+# Import our direct implementation
+from .agent import get_reddit_data
+
+logger = logging.getLogger(__name__)
+
+class RedditDataTool(BaseTool):
+    """A tool for retrieving Reddit posts from a specified subreddit."""
+    
+    def __init__(self, **kwargs):
+        """Initialize the RedditDataTool."""
+        super().__init__(
+            name="RedditDataTool",
+            description="""
+            Fetch recent posts from a specified subreddit using MCP.
+            
+            Args:
+                subreddit: The name of the subreddit to fetch posts from (e.g., 'Bitcoin').
+                limit: Maximum number of posts to fetch. Defaults to 15 if not specified by the agent.
+                session_id: Session identifier (for tracking purposes). Optional - will use a default if not provided.
+            
+            Returns:
+                JSON string containing post data or an error message in JSON format: {"error": "description"}.
+            """,
+            **kwargs
+        )
+    
+    def _run(self, subreddit: str, limit: int = 15, session_id: Optional[str] = None) -> str:
+        """Execute the tool to fetch Reddit data."""
+        logger.info(f"RedditDataTool executing with subreddit={subreddit}, limit={limit}")
+        return get_reddit_data(subreddit, limit, session_id) 